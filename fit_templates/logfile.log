[INFO    ] State start
[INFO    ]   Scheduler at: tcp://188.184.96.137:8786
[INFO    ]   dashboard at:  http://188.184.96.137:8787/status
[INFO    ] Registering Worker plugin shuffle
[INFO    ] Adaptive scaling started: minimum=8 maximum=8
[INFO    ] Receive client connection: Client-6a9d48b5-8802-11f0-8b2a-fa163e97f17b
[INFO    ] Starting established connection to tcp://188.184.96.137:51600
[INFO    ] Event loop was unresponsive in Scheduler for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
[INFO    ] Register worker <WorkerState 'tcp://188.185.210.221:10000', name: CernCluster-1, status: init, memory: 0, processing: 0>
[INFO    ] Starting worker compute stream, tcp://188.185.210.221:10000
[INFO    ] Starting established connection to tcp://188.185.210.221:54862
[INFO    ] Grouping samples during processing
[INFO    ] Grouping samples configuration: {'TTto4Q': ['TTto4Q'], 'Vjets': ['VJets'], 'SingleTop': ['TWminus', 'TWplus']}
[INFO    ] Working on group of datasets: TTto4Q (4 datasets)
[INFO    ] Total number of events: 390111821
[INFO    ] Register worker <WorkerState 'tcp://188.185.213.228:10000', name: CernCluster-0, status: init, memory: 0, processing: 0>
[INFO    ] Starting worker compute stream, tcp://188.185.213.228:10000
[INFO    ] Starting established connection to tcp://188.185.213.228:40460
[INFO    ] Register worker <WorkerState 'tcp://188.185.210.142:10000', name: CernCluster-2, status: init, memory: 0, processing: 0>
[INFO    ] Starting worker compute stream, tcp://188.185.210.142:10000
[INFO    ] Starting established connection to tcp://188.185.210.142:41160
[INFO    ] Register worker <WorkerState 'tcp://188.185.214.10:10000', name: CernCluster-6, status: init, memory: 0, processing: 0>
[INFO    ] Starting worker compute stream, tcp://188.185.214.10:10000
[INFO    ] Starting established connection to tcp://188.185.214.10:41838
[INFO    ] Register worker <WorkerState 'tcp://188.185.210.157:10000', name: CernCluster-5, status: init, memory: 0, processing: 0>
[INFO    ] Starting worker compute stream, tcp://188.185.210.157:10000
[INFO    ] Starting established connection to tcp://188.185.210.157:59790
[INFO    ] Register worker <WorkerState 'tcp://188.185.213.149:10000', name: CernCluster-3, status: init, memory: 0, processing: 0>
[INFO    ] Starting worker compute stream, tcp://188.185.213.149:10000
[INFO    ] Starting established connection to tcp://188.185.213.149:42434
[INFO    ] Register worker <WorkerState 'tcp://128.142.161.106:10000', name: CernCluster-4, status: init, memory: 0, processing: 0>
[INFO    ] Starting worker compute stream, tcp://128.142.161.106:10000
[INFO    ] Starting established connection to tcp://128.142.161.106:56334
[INFO    ] Adaptive scaling stopped: minimum=8 maximum=8
[INFO    ] Retire worker addresses ('CernCluster-0', 'CernCluster-7', 'CernCluster-1', 'CernCluster-2', 'CernCluster-6', 'CernCluster-4', 'CernCluster-5', 'CernCluster-3')
[INFO    ] Received 'close-stream' from tcp://188.185.213.228:40460; closing.
[INFO    ] Received 'close-stream' from tcp://188.185.210.221:54862; closing.
[INFO    ] Remove worker <WorkerState 'tcp://188.185.213.228:10000', name: CernCluster-0, status: closing, memory: 1, processing: 0> (stimulus_id='handle-worker-cleanup-1756821417.8369324')
[INFO    ] Received 'close-stream' from tcp://128.142.161.106:56334; closing.
[INFO    ] Remove worker <WorkerState 'tcp://188.185.210.221:10000', name: CernCluster-1, status: closing, memory: 1, processing: 0> (stimulus_id='handle-worker-cleanup-1756821417.8373353')
[INFO    ] Remove worker <WorkerState 'tcp://128.142.161.106:10000', name: CernCluster-4, status: closing, memory: 1, processing: 0> (stimulus_id='handle-worker-cleanup-1756821417.8386214')
[WARNING ] Removing worker 'tcp://128.142.161.106:10000' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-417ace5c6e3a4528a80b7aa7f4c12bc0'} (stimulus_id='handle-worker-cleanup-1756821417.8386214')
[INFO    ] Received 'close-stream' from tcp://188.185.210.157:59790; closing.
[INFO    ] Received 'close-stream' from tcp://188.185.213.149:42434; closing.
[INFO    ] Received 'close-stream' from tcp://188.185.210.142:41160; closing.
[INFO    ] Received 'close-stream' from tcp://188.185.214.10:41838; closing.
[INFO    ] Closing scheduler. Reason: unknown
[INFO    ] Remove worker <WorkerState 'tcp://188.185.210.157:10000', name: CernCluster-5, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1756821417.8405826')
[INFO    ] Remove worker <WorkerState 'tcp://188.185.213.149:10000', name: CernCluster-3, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1756821417.840831')
[INFO    ] Remove worker <WorkerState 'tcp://188.185.210.142:10000', name: CernCluster-2, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1756821417.8411326')
[INFO    ] Remove worker <WorkerState 'tcp://188.185.214.10:10000', name: CernCluster-6, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1756821417.8413308')
[INFO    ] Lost all workers
[INFO    ] Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://188.184.96.137:8786 remote=tcp://128.142.161.106:56334>
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/tornado/gen.py", line 783, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/distributed/comm/tcp.py", line 262, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
[INFO    ] Scheduler closing all comms
[INFO    ] Grouping samples during processing
[INFO    ] Grouping samples configuration: {'TTto4Q': ['TTto4Q'], 'Vjets': ['VJets'], 'SingleTop': ['TWminus', 'TWplus']}
[INFO    ] Working on group of datasets: TTto4Q (4 datasets)
[INFO    ] Total number of events: 390111821
[INFO    ] Grouping samples during processing
[INFO    ] Grouping samples configuration: {'TTto4Q': ['TTto4Q'], 'Vjets': ['VJets'], 'SingleTop': ['TWminus', 'TWplus']}
[INFO    ] Working on group of datasets: TTto4Q (4 datasets)
[INFO    ] Total number of events: 390111821
[INFO    ] Grouping samples during processing
[INFO    ] Grouping samples configuration: {'TTto4Q': ['TTto4Q'], 'Vjets': ['VJets'], 'SingleTop': ['TWminus', 'TWplus']}
[INFO    ] Working on group of datasets: TTto4Q (4 datasets)
[INFO    ] Total number of events: 390111821
[INFO    ] Grouping samples during processing
[INFO    ] Grouping samples configuration: {'TTto4Q': ['TTto4Q'], 'Vjets': ['VJets'], 'SingleTop': ['TWminus', 'TWplus']}
[INFO    ] Working on group of datasets: TTto4Q (4 datasets)
[INFO    ] Total number of events: 390111821
[INFO    ] Grouping samples during processing
[INFO    ] Grouping samples configuration: {'TTto4Q': ['TTto4Q'], 'Vjets': ['VJets'], 'SingleTop': ['TWminus', 'TWplus']}
[INFO    ] Working on group of datasets: TTto4Q (4 datasets)
[INFO    ] Total number of events: 390111821
[INFO    ] Grouping samples during processing
[INFO    ] Grouping samples configuration: {'TTto4Q': ['TTto4Q'], 'Vjets': ['VJets'], 'SingleTop': ['TWminus', 'TWplus']}
[INFO    ] Working on group of datasets: TTto4Q (4 datasets)
[INFO    ] Total number of events: 390111821
[INFO    ] Grouping samples during processing
[INFO    ] Grouping samples configuration: {'TTto4Q': ['TTto4Q'], 'Vjets': ['VJets'], 'SingleTop': ['TWminus', 'TWplus']}
[INFO    ] Working on group of datasets: TTto4Q (4 datasets)
[INFO    ] Total number of events: 390111821
[INFO    ] Working on group of datasets: Vjets (32 datasets)
[INFO    ] Total number of events: 67206019
[INFO    ] Reducing chunksize from 400000 to 336030 for dataset(s) Vjets
